{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Detecting Missing Values during Data Ingestion\n",
    "**Description**: You have a CSV file with missing values in some columns. Write a Python script to detect and report missing values during the ingestion process.\n",
    "\n",
    "**Steps**:\n",
    "1. Load data\n",
    "2. Check for missing values\n",
    "3. Report missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Report:\n",
      "id       0\n",
      "name     1\n",
      "age      1\n",
      "email    1\n",
      "dtype: int64\n",
      "Total missing values: 3\n",
      "\n",
      "Warning: Dataset contains missing values!\n",
      "\n",
      "Data Type Validation Errors:\n",
      "Row 1 - Field 'age' has invalid type 'str', value: 30\n",
      "\n",
      "Duplicate Records Detected:\n",
      "   id     name  age                email\n",
      "1   2      Bob   30      bob@example.com\n",
      "2   3  Charlie   22  charlie@example.com\n",
      "3   2      Bob   30      bob@example.com\n",
      "6   3  Charlie   22  charlie@example.com\n",
      "Number of duplicate rows found: 4\n",
      "Number of rows after removing duplicates: 5\n",
      "\n",
      "Missing Values Report:\n",
      "a    1\n",
      "b    1\n",
      "dtype: int64\n",
      "Total missing values: 2\n",
      "\n",
      "Warning: Dataset contains missing values!\n",
      "\n",
      "Duplicate Records Detected:\n",
      "   col1 col2\n",
      "1     2    b\n",
      "2     2    b\n",
      "Number of duplicate rows found: 2\n",
      "Number of rows after removing duplicates: 3\n",
      "\n",
      "Warning: DataFrame is empty, no duplicates to remove.\n",
      "All records conform to the expected schema.\n",
      "\n",
      "Data Type Validation Errors:\n",
      "Row 1 - Field 'x' has invalid type 'str', value: two\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unittest\n",
    "\n",
    "# ------------------ Task 1: Detect Missing Values ------------------\n",
    "\n",
    "def detect_missing_values(df):\n",
    "    \"\"\"\n",
    "    Detect and report missing values in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame to check for missing values.\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: Count of missing values per column.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty\")\n",
    "    \n",
    "    missing_report = df.isnull().sum()\n",
    "    total_missing = missing_report.sum()\n",
    "    print(\"Missing Values Report:\")\n",
    "    print(missing_report)\n",
    "    print(f\"Total missing values: {total_missing}\\n\")\n",
    "    if total_missing > 0:\n",
    "        print(\"Warning: Dataset contains missing values!\\n\")\n",
    "    else:\n",
    "        print(\"No missing values detected.\\n\")\n",
    "    return missing_report\n",
    "\n",
    "# ------------------ Task 2: Validate Data Types ------------------\n",
    "\n",
    "def validate_data_types(data, schema):\n",
    "    \"\"\"\n",
    "    Validate if the data matches the expected schema types.\n",
    "    \n",
    "    Args:\n",
    "        data (list of dict): List of records (JSON-like).\n",
    "        schema (dict): Dictionary mapping field names to expected type(s).\n",
    "        \n",
    "    Returns:\n",
    "        list: List of errors as tuples (record_index, field, value, actual_type).\n",
    "    \"\"\"\n",
    "    if not isinstance(data, list):\n",
    "        raise TypeError(\"Data should be a list of dictionaries\")\n",
    "    if not isinstance(schema, dict):\n",
    "        raise TypeError(\"Schema should be a dictionary\")\n",
    "    \n",
    "    errors = []\n",
    "    for i, record in enumerate(data):\n",
    "        if not isinstance(record, dict):\n",
    "            errors.append((i, None, record, type(record).__name__))\n",
    "            continue\n",
    "        for field, expected_type in schema.items():\n",
    "            value = record.get(field, None)\n",
    "            if not isinstance(value, expected_type):\n",
    "                errors.append((i, field, value, type(value).__name__))\n",
    "    if errors:\n",
    "        print(\"Data Type Validation Errors:\")\n",
    "        for err in errors:\n",
    "            print(f\"Row {err[0]} - Field '{err[1]}' has invalid type '{err[3]}', value: {err[2]}\")\n",
    "    else:\n",
    "        print(\"All records conform to the expected schema.\")\n",
    "    print()\n",
    "    return errors\n",
    "\n",
    "# ------------------ Task 3: Remove Duplicate Records ------------------\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Find and remove duplicate rows in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame to check for duplicates.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "    if df.empty:\n",
    "        print(\"Warning: DataFrame is empty, no duplicates to remove.\")\n",
    "        return df\n",
    "    \n",
    "    duplicate_rows = df[df.duplicated(keep=False)]\n",
    "    if not duplicate_rows.empty:\n",
    "        print(\"Duplicate Records Detected:\")\n",
    "        print(duplicate_rows)\n",
    "        print(f\"Number of duplicate rows found: {duplicate_rows.shape[0]}\")\n",
    "        df_cleaned = df.drop_duplicates()\n",
    "        print(f\"Number of rows after removing duplicates: {df_cleaned.shape[0]}\\n\")\n",
    "    else:\n",
    "        print(\"No duplicates found.\\n\")\n",
    "        df_cleaned = df\n",
    "    return df_cleaned\n",
    "\n",
    "# ------------------ Example Usage ------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulated CSV DataFrame\n",
    "    data_csv = {\n",
    "        \"id\": [1, 2, 3, 4, 5],\n",
    "        \"name\": [\"Alice\", None, \"Charlie\", \"David\", \"Eva\"],\n",
    "        \"age\": [25, 30, None, 40, 35],\n",
    "        \"email\": [\"alice@example.com\", \"bob@example.com\", \"charlie@example.com\", None, \"eva@example.com\"]\n",
    "    }\n",
    "    df = pd.DataFrame(data_csv)\n",
    "    detect_missing_values(df)\n",
    "    \n",
    "    # Simulated JSON-like data\n",
    "    data_json = [\n",
    "        {\"id\": 1, \"name\": \"Alice\", \"age\": 25, \"email\": \"alice@example.com\"},\n",
    "        {\"id\": 2, \"name\": \"Bob\", \"age\": \"30\", \"email\": \"bob@example.com\"},  # age as string (invalid)\n",
    "        {\"id\": 3, \"name\": \"Charlie\", \"age\": 22, \"email\": \"charlie@example.com\"},\n",
    "        {\"id\": 4, \"name\": \"David\", \"age\": 40, \"email\": None}               # email can be None\n",
    "    ]\n",
    "    expected_schema = {\n",
    "        \"id\": int,\n",
    "        \"name\": str,\n",
    "        \"age\": int,\n",
    "        \"email\": (str, type(None))\n",
    "    }\n",
    "    validate_data_types(data_json, expected_schema)\n",
    "    \n",
    "    # Simulated duplicates DataFrame\n",
    "    data_duplicates = {\n",
    "        \"id\": [1, 2, 3, 2, 4, 5, 3],\n",
    "        \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"Bob\", \"David\", \"Eva\", \"Charlie\"],\n",
    "        \"age\": [25, 30, 22, 30, 40, 35, 22],\n",
    "        \"email\": [\n",
    "            \"alice@example.com\", \"bob@example.com\", \"charlie@example.com\",\n",
    "            \"bob@example.com\", \"david@example.com\", \"eva@example.com\", \"charlie@example.com\"\n",
    "        ]\n",
    "    }\n",
    "    df_dup = pd.DataFrame(data_duplicates)\n",
    "    remove_duplicates(df_dup)\n",
    "\n",
    "# ------------------ Unit Tests ------------------\n",
    "\n",
    "class TestDataQualityFunctions(unittest.TestCase):\n",
    "    \n",
    "    def test_detect_missing_values(self):\n",
    "        df_test = pd.DataFrame({\n",
    "            'a': [1, None, 3],\n",
    "            'b': ['x', 'y', None]\n",
    "        })\n",
    "        result = detect_missing_values(df_test)\n",
    "        self.assertEqual(result['a'], 1)\n",
    "        self.assertEqual(result['b'], 1)\n",
    "        \n",
    "    def test_detect_missing_values_invalid_input(self):\n",
    "        with self.assertRaises(TypeError):\n",
    "            detect_missing_values(\"not a dataframe\")\n",
    "        with self.assertRaises(ValueError):\n",
    "            detect_missing_values(pd.DataFrame())\n",
    "    \n",
    "    def test_validate_data_types(self):\n",
    "        data = [{\"x\": 1, \"y\": \"a\"}, {\"x\": 2, \"y\": \"b\"}]\n",
    "        schema = {\"x\": int, \"y\": str}\n",
    "        errors = validate_data_types(data, schema)\n",
    "        self.assertEqual(len(errors), 0)\n",
    "        \n",
    "        # Introduce error\n",
    "        data[1][\"x\"] = \"two\"\n",
    "        errors = validate_data_types(data, schema)\n",
    "        self.assertEqual(len(errors), 1)\n",
    "    \n",
    "    def test_validate_data_types_invalid_input(self):\n",
    "        with self.assertRaises(TypeError):\n",
    "            validate_data_types(\"not a list\", {\"x\": int})\n",
    "        with self.assertRaises(TypeError):\n",
    "            validate_data_types([{\"x\": 1}], \"not a dict\")\n",
    "    \n",
    "    def test_remove_duplicates(self):\n",
    "        df = pd.DataFrame({\n",
    "            'col1': [1, 2, 2, 3],\n",
    "            'col2': ['a', 'b', 'b', 'c']\n",
    "        })\n",
    "        cleaned_df = remove_duplicates(df)\n",
    "        self.assertEqual(len(cleaned_df), 3)\n",
    "        \n",
    "    def test_remove_duplicates_invalid_input(self):\n",
    "        with self.assertRaises(TypeError):\n",
    "            remove_duplicates(\"not a dataframe\")\n",
    "    \n",
    "    def test_remove_duplicates_empty_df(self):\n",
    "        empty_df = pd.DataFrame()\n",
    "        cleaned_df = remove_duplicates(empty_df)\n",
    "        self.assertTrue(cleaned_df.empty)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], exit=False)  # Run unit tests in Jupyter or interactive env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Report:\n",
      "id       0\n",
      "name     1\n",
      "age      1\n",
      "email    1\n",
      "dtype: int64\n",
      "Total missing values: 3\n",
      "\n",
      "Warning: Dataset contains missing values!\n",
      "\n",
      "Data Type Validation Report:\n",
      "Row 1 - Field 'age' has invalid type 'str', value: 30\n",
      "\n",
      "Duplicate Records Detection:\n",
      "   id     name  age                email\n",
      "1   2      Bob   30      bob@example.com\n",
      "2   3  Charlie   22  charlie@example.com\n",
      "3   2      Bob   30      bob@example.com\n",
      "6   3  Charlie   22  charlie@example.com\n",
      "Number of duplicate rows found: 4\n",
      "Number of rows after removing duplicates: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# ------------------ Task 1: Detect Missing Values ------------------\n",
    "\n",
    "# Simulate CSV data as DataFrame with missing values\n",
    "data_csv = {\n",
    "    \"id\": [1, 2, 3, 4, 5],\n",
    "    \"name\": [\"Alice\", None, \"Charlie\", \"David\", \"Eva\"],\n",
    "    \"age\": [25, 30, None, 40, 35],\n",
    "    \"email\": [\"alice@example.com\", \"bob@example.com\", \"charlie@example.com\", None, \"eva@example.com\"]\n",
    "}\n",
    "df = pd.DataFrame(data_csv)\n",
    "\n",
    "def detect_missing_values(df):\n",
    "    missing_report = df.isnull().sum()\n",
    "    total_missing = missing_report.sum()\n",
    "    print(\"Missing Values Report:\")\n",
    "    print(missing_report)\n",
    "    print(f\"Total missing values: {total_missing}\\n\")\n",
    "    if total_missing > 0:\n",
    "        print(\"Warning: Dataset contains missing values!\\n\")\n",
    "    else:\n",
    "        print(\"No missing values detected.\\n\")\n",
    "\n",
    "detect_missing_values(df)\n",
    "\n",
    "# ------------------ Task 2: Validate Data Types ------------------\n",
    "\n",
    "# Simulate JSON data as a Python list of dicts (like extracted from JSON)\n",
    "data_json = [\n",
    "    {\"id\": 1, \"name\": \"Alice\", \"age\": 25, \"email\": \"alice@example.com\"},\n",
    "    {\"id\": 2, \"name\": \"Bob\", \"age\": \"30\", \"email\": \"bob@example.com\"},  # age as string (invalid)\n",
    "    {\"id\": 3, \"name\": \"Charlie\", \"age\": 22, \"email\": \"charlie@example.com\"},\n",
    "    {\"id\": 4, \"name\": \"David\", \"age\": 40, \"email\": None}               # email as None (acceptable as string type)\n",
    "]\n",
    "\n",
    "# Expected schema: field -> type\n",
    "expected_schema = {\n",
    "    \"id\": int,\n",
    "    \"name\": str,\n",
    "    \"age\": int,\n",
    "    \"email\": (str, type(None))  # email can be string or None (nullable)\n",
    "}\n",
    "\n",
    "def validate_data_types(data, schema):\n",
    "    print(\"Data Type Validation Report:\")\n",
    "    errors = []\n",
    "    for i, record in enumerate(data):\n",
    "        for field, expected_type in schema.items():\n",
    "            value = record.get(field, None)\n",
    "            if not isinstance(value, expected_type):\n",
    "                errors.append((i, field, value, type(value).__name__))\n",
    "    if errors:\n",
    "        for err in errors:\n",
    "            print(f\"Row {err[0]} - Field '{err[1]}' has invalid type '{err[3]}', value: {err[2]}\")\n",
    "    else:\n",
    "        print(\"All records conform to the expected schema.\")\n",
    "    print()\n",
    "\n",
    "validate_data_types(data_json, expected_schema)\n",
    "\n",
    "# ------------------ Task 3: Remove Duplicate Records ------------------\n",
    "\n",
    "# Simulate dataset with duplicates\n",
    "data_duplicates = {\n",
    "    \"id\": [1, 2, 3, 2, 4, 5, 3],\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"Bob\", \"David\", \"Eva\", \"Charlie\"],\n",
    "    \"age\": [25, 30, 22, 30, 40, 35, 22],\n",
    "    \"email\": [\n",
    "        \"alice@example.com\", \"bob@example.com\", \"charlie@example.com\",\n",
    "        \"bob@example.com\", \"david@example.com\", \"eva@example.com\", \"charlie@example.com\"\n",
    "    ]\n",
    "}\n",
    "df_dup = pd.DataFrame(data_duplicates)\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    print(\"Duplicate Records Detection:\")\n",
    "    duplicate_rows = df[df.duplicated(keep=False)]\n",
    "    if not duplicate_rows.empty:\n",
    "        print(duplicate_rows)\n",
    "        print(f\"Number of duplicate rows found: {duplicate_rows.shape[0]}\")\n",
    "        df_cleaned = df.drop_duplicates()\n",
    "        print(f\"Number of rows after removing duplicates: {df_cleaned.shape[0]}\\n\")\n",
    "    else:\n",
    "        print(\"No duplicates found.\\n\")\n",
    "        df_cleaned = df\n",
    "    return df_cleaned\n",
    "\n",
    "df_clean = remove_duplicates(df_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Validate Data Types during Extraction\n",
    "**Description**: You have a JSON file that should have specific data types for each field. Write a script to validate if the data types match the expected schema.\n",
    "\n",
    "**Steps**:\n",
    "1. Define expected schema\n",
    "2. Validate data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Remove Duplicate Records in Data\n",
    "**Description**: You have a dataset with duplicate entries. Write a Python script to find and remove duplicate records using Pandas.\n",
    "\n",
    "**Steps**:\n",
    "1. Find duplicate records\n",
    "2. Remove duplicates\n",
    "3. Report results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
