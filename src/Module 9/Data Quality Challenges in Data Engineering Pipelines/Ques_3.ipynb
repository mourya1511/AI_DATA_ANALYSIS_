{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Management for Data Quality\n",
    "**Description**: Store and use metadata to manage data quality in a pipeline.\n",
    "\n",
    "**Steps**:\n",
    "1. Load metadata\n",
    "2. Load data\n",
    "3. Use metadata to validate data quality\n",
    "4. Show valid data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MetadataValidator:üîç Running Metadata Validation...\n",
      "INFO:MetadataValidator:‚úÖ All required columns are present.\n",
      "WARNING:MetadataValidator:‚ö†Ô∏è Data type mismatches:\n",
      "WARNING:MetadataValidator: - Age @ row 1: Thirty\n",
      "WARNING:MetadataValidator:‚ö†Ô∏è Non-nullable column 'CustomerID' has null values.\n",
      "WARNING:MetadataValidator:‚ö†Ô∏è Non-nullable column 'Name' has null values.\n",
      "INFO:MetadataValidator:‚úÖ Validated Data:\n",
      "INFO:MetadataValidator:üîç Running Metadata Validation...\n",
      "INFO:MetadataValidator:‚úÖ All required columns are present.\n",
      "INFO:MetadataValidator:‚úÖ Data types are valid.\n",
      "INFO:MetadataValidator:‚úÖ Validated Data:\n",
      "INFO:MetadataValidator:üîç Running Metadata Validation...\n",
      "INFO:MetadataValidator:‚úÖ All required columns are present.\n",
      "WARNING:MetadataValidator:‚ö†Ô∏è Data type mismatches:\n",
      "WARNING:MetadataValidator: - Age @ row 0: twenty\n",
      "WARNING:MetadataValidator:‚ö†Ô∏è Non-nullable column 'CustomerID' has null values.\n",
      "WARNING:MetadataValidator:‚ö†Ô∏è Non-nullable column 'Name' has null values.\n",
      "INFO:MetadataValidator:‚úÖ Validated Data:\n",
      "INFO:MetadataValidator:üß™ All tests passed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID   Name          Email Age\n",
      "0         1.0  Alice  a@example.com  25\n",
      "   CustomerID  Name       Email  Age\n",
      "0           1  Test  x@test.com   22\n",
      "1           2  User  y@test.com   33\n",
      "Empty DataFrame\n",
      "Columns: [CustomerID, Name, Email, Age]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# -------------------- Logging Setup --------------------\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"MetadataValidator\")\n",
    "\n",
    "# -------------------- Sample Metadata --------------------\n",
    "metadata = {\n",
    "    \"CustomerID\": {\"dtype\": \"int\", \"nullable\": False},\n",
    "    \"Name\": {\"dtype\": \"str\", \"nullable\": False},\n",
    "    \"Email\": {\"dtype\": \"str\", \"nullable\": True},\n",
    "    \"Age\": {\"dtype\": \"int\", \"nullable\": True}\n",
    "}\n",
    "\n",
    "# -------------------- Simulated Data --------------------\n",
    "sample_data = {\n",
    "    \"CustomerID\": [1, 2, 3, None],\n",
    "    \"Name\": [\"Alice\", \"Bob\", None, \"David\"],\n",
    "    \"Email\": [\"a@example.com\", \"b@example.com\", None, \"d@example.com\"],\n",
    "    \"Age\": [25, \"Thirty\", 30, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sample_data)\n",
    "\n",
    "# -------------------- Validation Functions --------------------\n",
    "\n",
    "def validate_column_presence(df, metadata):\n",
    "    missing_cols = [col for col in metadata if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"‚ùå Missing columns: {missing_cols}\")\n",
    "    logger.info(\"‚úÖ All required columns are present.\")\n",
    "\n",
    "def validate_data_types(df, metadata):\n",
    "    issues = []\n",
    "    for col, rules in metadata.items():\n",
    "        expected_type = rules[\"dtype\"]\n",
    "        for i, val in enumerate(df[col]):\n",
    "            if pd.isnull(val):\n",
    "                continue\n",
    "            try:\n",
    "                if expected_type == \"int\":\n",
    "                    int(val)\n",
    "                elif expected_type == \"str\" and not isinstance(val, str):\n",
    "                    raise ValueError\n",
    "            except Exception as e:\n",
    "                issues.append((col, i, val))\n",
    "    if issues:\n",
    "        logger.warning(\"‚ö†Ô∏è Data type mismatches:\")\n",
    "        for col, row, val in issues:\n",
    "            logger.warning(f\" - {col} @ row {row}: {val}\")\n",
    "    else:\n",
    "        logger.info(\"‚úÖ Data types are valid.\")\n",
    "\n",
    "def validate_nullability(df, metadata):\n",
    "    for col, rules in metadata.items():\n",
    "        if not rules[\"nullable\"] and df[col].isnull().any():\n",
    "            logger.warning(f\"‚ö†Ô∏è Non-nullable column '{col}' has null values.\")\n",
    "\n",
    "def get_valid_rows(df, metadata):\n",
    "    valid_mask = pd.Series([True] * len(df))\n",
    "    for col, rules in metadata.items():\n",
    "        if not rules[\"nullable\"]:\n",
    "            valid_mask &= df[col].notnull()\n",
    "        expected_type = rules[\"dtype\"]\n",
    "        def is_valid(val):\n",
    "            if pd.isnull(val): return True\n",
    "            try:\n",
    "                if expected_type == \"int\":\n",
    "                    int(val)\n",
    "                elif expected_type == \"str\":\n",
    "                    return isinstance(val, str)\n",
    "                return True\n",
    "            except:\n",
    "                return False\n",
    "        valid_mask &= df[col].apply(is_valid)\n",
    "    return df[valid_mask].copy()\n",
    "\n",
    "# -------------------- Main Validation Logic --------------------\n",
    "\n",
    "def run_validation_pipeline(df, metadata):\n",
    "    try:\n",
    "        logger.info(\"üîç Running Metadata Validation...\")\n",
    "        validate_column_presence(df, metadata)\n",
    "        validate_data_types(df, metadata)\n",
    "        validate_nullability(df, metadata)\n",
    "        valid_df = get_valid_rows(df, metadata)\n",
    "        logger.info(\"‚úÖ Validated Data:\")\n",
    "        print(valid_df)\n",
    "        return valid_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Validation Error: {e}\")\n",
    "        return pd.DataFrame()  # return empty frame on failure\n",
    "\n",
    "# -------------------- Basic Unit Tests --------------------\n",
    "\n",
    "def test_validation():\n",
    "    test_df = pd.DataFrame({\n",
    "        \"CustomerID\": [1, 2],\n",
    "        \"Name\": [\"Test\", \"User\"],\n",
    "        \"Email\": [\"x@test.com\", \"y@test.com\"],\n",
    "        \"Age\": [22, 33]\n",
    "    })\n",
    "    result = run_validation_pipeline(test_df, metadata)\n",
    "    assert not result.empty, \"Validation failed on correct data\"\n",
    "    assert len(result) == 2, \"Not all valid rows passed\"\n",
    "\n",
    "    invalid_df = pd.DataFrame({\n",
    "        \"CustomerID\": [1, None],\n",
    "        \"Name\": [\"Test\", None],\n",
    "        \"Email\": [\"x@test.com\", \"y@test.com\"],\n",
    "        \"Age\": [\"twenty\", 33]\n",
    "    })\n",
    "    result2 = run_validation_pipeline(invalid_df, metadata)\n",
    "    assert len(result2) == 0, \"Invalid rows should be excluded\"\n",
    "\n",
    "# -------------------- Execution --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    final_df = run_validation_pipeline(df, metadata)\n",
    "    test_validation()\n",
    "    logger.info(\"üß™ All tests passed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MetadataValidator:üîç Starting metadata-based validation...\n",
      "INFO:MetadataValidator:‚úÖ All required columns are present.\n",
      "WARNING:MetadataValidator:‚ö†Ô∏è Data type mismatches found:\n",
      "WARNING:MetadataValidator: - Column: Age, Row: 1, Value: Thirty\n",
      "WARNING:MetadataValidator:‚ö†Ô∏è Column 'CustomerID' has 1 null values but is marked non-nullable.\n",
      "WARNING:MetadataValidator:‚ö†Ô∏è Column 'Name' has 1 null values but is marked non-nullable.\n",
      "INFO:MetadataValidator:‚úÖ Final Valid Data:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID   Name          Email Age\n",
      "0         1.0  Alice  a@example.com  25\n"
     ]
    }
   ],
   "source": [
    "# write your code from here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# ------------------- Setup Logging -------------------\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"MetadataValidator\")\n",
    "\n",
    "# ------------------- Sample Metadata Definition -------------------\n",
    "metadata = {\n",
    "    \"CustomerID\": {\"dtype\": \"int\", \"nullable\": False},\n",
    "    \"Name\": {\"dtype\": \"str\", \"nullable\": False},\n",
    "    \"Email\": {\"dtype\": \"str\", \"nullable\": True},\n",
    "    \"Age\": {\"dtype\": \"int\", \"nullable\": True}\n",
    "}\n",
    "\n",
    "# ------------------- Sample Data -------------------\n",
    "sample_data = {\n",
    "    \"CustomerID\": [1, 2, 3, None],\n",
    "    \"Name\": [\"Alice\", \"Bob\", None, \"David\"],\n",
    "    \"Email\": [\"a@example.com\", \"b@example.com\", None, \"d@example.com\"],\n",
    "    \"Age\": [25, \"Thirty\", 30, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sample_data)\n",
    "\n",
    "# ------------------- Validation Functions -------------------\n",
    "\n",
    "def validate_column_presence(df, metadata):\n",
    "    missing_cols = [col for col in metadata if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"‚ùå Missing columns: {missing_cols}\")\n",
    "    logger.info(\"‚úÖ All required columns are present.\")\n",
    "\n",
    "def validate_data_types(df, metadata):\n",
    "    issues = []\n",
    "    for col, rules in metadata.items():\n",
    "        expected_type = rules[\"dtype\"]\n",
    "        for i, val in enumerate(df[col]):\n",
    "            if pd.isnull(val):\n",
    "                continue\n",
    "            if expected_type == \"int\":\n",
    "                try:\n",
    "                    int(val)\n",
    "                except:\n",
    "                    issues.append((col, i, val))\n",
    "            elif expected_type == \"str\":\n",
    "                if not isinstance(val, str):\n",
    "                    issues.append((col, i, val))\n",
    "    if issues:\n",
    "        logger.warning(\"‚ö†Ô∏è Data type mismatches found:\")\n",
    "        for issue in issues:\n",
    "            logger.warning(f\" - Column: {issue[0]}, Row: {issue[1]}, Value: {issue[2]}\")\n",
    "    else:\n",
    "        logger.info(\"‚úÖ All data types are valid.\")\n",
    "\n",
    "def validate_nullability(df, metadata):\n",
    "    for col, rules in metadata.items():\n",
    "        if not rules[\"nullable\"] and df[col].isnull().any():\n",
    "            null_count = df[col].isnull().sum()\n",
    "            logger.warning(f\"‚ö†Ô∏è Column '{col}' has {null_count} null values but is marked non-nullable.\")\n",
    "\n",
    "# ------------------- Filter Valid Rows -------------------\n",
    "\n",
    "def get_valid_rows(df, metadata):\n",
    "    valid_mask = pd.Series([True] * len(df))\n",
    "    for col, rules in metadata.items():\n",
    "        if not rules[\"nullable\"]:\n",
    "            valid_mask &= df[col].notnull()\n",
    "\n",
    "        expected_type = rules[\"dtype\"]\n",
    "        def is_valid_type(val):\n",
    "            if pd.isnull(val):\n",
    "                return True\n",
    "            try:\n",
    "                if expected_type == \"int\":\n",
    "                    int(val)\n",
    "                elif expected_type == \"str\":\n",
    "                    return isinstance(val, str)\n",
    "                return True\n",
    "            except:\n",
    "                return False\n",
    "\n",
    "        valid_mask &= df[col].apply(is_valid_type)\n",
    "\n",
    "    valid_df = df[valid_mask].copy()\n",
    "    return valid_df\n",
    "\n",
    "# ------------------- Execution -------------------\n",
    "\n",
    "def run_metadata_validation():\n",
    "    logger.info(\"üîç Starting metadata-based validation...\")\n",
    "\n",
    "    try:\n",
    "        validate_column_presence(df, metadata)\n",
    "        validate_data_types(df, metadata)\n",
    "        validate_nullability(df, metadata)\n",
    "\n",
    "        valid_df = get_valid_rows(df, metadata)\n",
    "        logger.info(\"‚úÖ Final Valid Data:\")\n",
    "        print(valid_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Validation failed: {e}\")\n",
    "\n",
    "# ------------------- Run -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_metadata_validation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
