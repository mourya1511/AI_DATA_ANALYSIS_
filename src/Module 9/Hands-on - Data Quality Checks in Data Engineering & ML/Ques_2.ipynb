{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Adversarial Validation for Data Drift\n",
    "Description: Create and train a classifier that distinguishes between train and test datasets, using the classifierâ€™s performance to infer data drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isinf' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 155\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m auc_with_drift \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected drift AUC > 0.7\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# Run unit tests\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     \u001b[43mtest_validate_dataframes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     test_adversarial_validation()\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll tests passed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 126\u001b[0m, in \u001b[0;36mtest_validate_dataframes\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m df6 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[43mvalidate_dataframes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf6\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m, in \u001b[0;36mvalidate_dataframes\u001b[0;34m(df_train, df_test)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput data contains missing values. Please handle them before.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check infinite values\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(df_train\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput data contains infinite values. Please handle them before.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Check column data types consistency\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isinf' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def validate_dataframes(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Validate input dataframes for adversarial validation.\n",
    "    Checks types, shape, missing values, infinite values, and data types.\n",
    "    Raises:\n",
    "        TypeError, ValueError\n",
    "    \"\"\"\n",
    "    if not isinstance(df_train, pd.DataFrame) or not isinstance(df_test, pd.DataFrame):\n",
    "        raise TypeError(\"Both inputs must be pandas DataFrames.\")\n",
    "    \n",
    "    if df_train.shape[1] != df_test.shape[1]:\n",
    "        raise ValueError(\"Train and test data must have the same number of columns.\")\n",
    "    \n",
    "    # Check missing values\n",
    "    if df_train.isnull().any().any() or df_test.isnull().any().any():\n",
    "        raise ValueError(\"Input data contains missing values. Please handle them before.\")\n",
    "    \n",
    "    # Check infinite values\n",
    "    if np.isinf(df_train.values).any() or np.isinf(df_test.values).any():\n",
    "        raise ValueError(\"Input data contains infinite values. Please handle them before.\")\n",
    "    \n",
    "    # Check column data types consistency\n",
    "    for col_train, col_test in zip(df_train.dtypes, df_test.dtypes):\n",
    "        if col_train != col_test:\n",
    "            raise ValueError(\"Data type mismatch between train and test columns.\")\n",
    "\n",
    "def adversarial_validation(df_train, df_test, classifier=None, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Performs adversarial validation by training a classifier to distinguish train vs test samples.\n",
    "\n",
    "    Parameters:\n",
    "    - df_train (pd.DataFrame): Training dataset features\n",
    "    - df_test (pd.DataFrame): Test dataset features\n",
    "    - classifier: sklearn classifier instance (default RandomForestClassifier)\n",
    "    - test_size (float): Fraction of data to use for validation split\n",
    "    - random_state (int): Random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - auc_score (float): ROC-AUC score on validation set\n",
    "    \"\"\"\n",
    "    validate_dataframes(df_train, df_test)\n",
    "\n",
    "    # Label datasets: 0 for train, 1 for test\n",
    "    df_train_labeled = df_train.copy()\n",
    "    df_train_labeled['origin'] = 0\n",
    "\n",
    "    df_test_labeled = df_test.copy()\n",
    "    df_test_labeled['origin'] = 1\n",
    "\n",
    "    combined = pd.concat([df_train_labeled, df_test_labeled], axis=0).reset_index(drop=True)\n",
    "\n",
    "    X = combined.drop(columns='origin')\n",
    "    y = combined['origin']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    if classifier is None:\n",
    "        classifier = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred_proba = classifier.predict_proba(X_val)[:, 1]\n",
    "    auc_score = roc_auc_score(y_val, y_pred_proba)\n",
    "\n",
    "    return auc_score\n",
    "\n",
    "# --------------------- Unit Tests ---------------------\n",
    "\n",
    "def test_validate_dataframes():\n",
    "    # Create valid dataframes\n",
    "    df1 = pd.DataFrame({'a': [1, 2], 'b': [3.0, 4.0]})\n",
    "    df2 = pd.DataFrame({'a': [5, 6], 'b': [7.0, 8.0]})\n",
    "\n",
    "    # Should pass without exceptions\n",
    "    validate_dataframes(df1, df2)\n",
    "\n",
    "    # Test type check\n",
    "    try:\n",
    "        validate_dataframes(df1, [1,2,3])\n",
    "    except TypeError:\n",
    "        pass\n",
    "    else:\n",
    "        raise AssertionError(\"TypeError not raised for non-DataFrame input\")\n",
    "\n",
    "    # Test shape mismatch\n",
    "    df3 = pd.DataFrame({'a': [1,2,3]})\n",
    "    try:\n",
    "        validate_dataframes(df1, df3)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    else:\n",
    "        raise AssertionError(\"ValueError not raised for shape mismatch\")\n",
    "\n",
    "    # Test missing values\n",
    "    df4 = pd.DataFrame({'a': [np.nan, 2], 'b': [3, 4]})\n",
    "    try:\n",
    "        validate_dataframes(df4, df2)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    else:\n",
    "        raise AssertionError(\"ValueError not raised for missing values\")\n",
    "\n",
    "    # Test infinite values\n",
    "    df5 = pd.DataFrame({'a': [np.inf, 2], 'b': [3, 4]})\n",
    "    try:\n",
    "        validate_dataframes(df5, df2)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    else:\n",
    "        raise AssertionError(\"ValueError not raised for infinite values\")\n",
    "\n",
    "    # Test dtype mismatch\n",
    "    df6 = pd.DataFrame({'a': [1,2], 'b': ['x', 'y']})\n",
    "    try:\n",
    "        validate_dataframes(df1, df6)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    else:\n",
    "        raise AssertionError(\"ValueError not raised for dtype mismatch\")\n",
    "\n",
    "def test_adversarial_validation():\n",
    "    # Create simple datasets\n",
    "    df_train = pd.DataFrame({\n",
    "        'f1': np.random.normal(0,1,100),\n",
    "        'f2': np.random.normal(5,2,100)\n",
    "    })\n",
    "    df_test_same = pd.DataFrame({\n",
    "        'f1': np.random.normal(0,1,50),\n",
    "        'f2': np.random.normal(5,2,50)\n",
    "    })\n",
    "    df_test_diff = pd.DataFrame({\n",
    "        'f1': np.random.normal(3,1,50),\n",
    "        'f2': np.random.normal(7,2,50)\n",
    "    })\n",
    "\n",
    "    auc_no_drift = adversarial_validation(df_train, df_test_same)\n",
    "    assert 0.4 <= auc_no_drift <= 0.6, \"Expected no drift AUC near 0.5\"\n",
    "\n",
    "    auc_with_drift = adversarial_validation(df_train, df_test_diff)\n",
    "    assert auc_with_drift > 0.7, \"Expected drift AUC > 0.7\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run unit tests\n",
    "    test_validate_dataframes()\n",
    "    test_adversarial_validation()\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "    # Example usage\n",
    "    np.random.seed(0)\n",
    "    train_data = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1, 1000),\n",
    "        'feature2': np.random.normal(5, 2, 1000),\n",
    "    })\n",
    "    test_data_with_drift = pd.DataFrame({\n",
    "        'feature1': np.random.normal(1, 1, 500),\n",
    "        'feature2': np.random.normal(6, 2, 500),\n",
    "    })\n",
    "\n",
    "    auc_score = adversarial_validation(train_data, test_data_with_drift)\n",
    "    print(f\"\\nAdversarial Validation ROC-AUC: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (No Drift): 0.4932 (Close to 0.5 means no drift)\n",
      "ROC-AUC (With Drift): 0.7384 (Closer to 1 means drift detected)\n"
     ]
    }
   ],
   "source": [
    "# write your code from here\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def validate_dataframes(df_train, df_test):\n",
    "    if not isinstance(df_train, pd.DataFrame) or not isinstance(df_test, pd.DataFrame):\n",
    "        raise TypeError(\"Both inputs must be pandas DataFrames.\")\n",
    "    if df_train.shape[1] != df_test.shape[1]:\n",
    "        raise ValueError(\"Train and test data must have the same number of columns.\")\n",
    "    if df_train.isnull().any().any() or df_test.isnull().any().any():\n",
    "        raise ValueError(\"Input data contains missing values. Please handle them before.\")\n",
    "\n",
    "def adversarial_validation(df_train, df_test, classifier=None, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Performs adversarial validation by training a classifier to distinguish train vs test samples.\n",
    "\n",
    "    Parameters:\n",
    "    - df_train (pd.DataFrame): Training dataset features\n",
    "    - df_test (pd.DataFrame): Test dataset features\n",
    "    - classifier: sklearn classifier instance (default RandomForestClassifier)\n",
    "    - test_size (float): Fraction of data to use for validation split\n",
    "    - random_state (int): Random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - auc_score (float): ROC-AUC score on validation set\n",
    "    \"\"\"\n",
    "\n",
    "    validate_dataframes(df_train, df_test)\n",
    "\n",
    "    # Label the datasets: 0 for train, 1 for test\n",
    "    df_train_labeled = df_train.copy()\n",
    "    df_train_labeled['origin'] = 0\n",
    "\n",
    "    df_test_labeled = df_test.copy()\n",
    "    df_test_labeled['origin'] = 1\n",
    "\n",
    "    # Combine datasets\n",
    "    combined = pd.concat([df_train_labeled, df_test_labeled], axis=0).reset_index(drop=True)\n",
    "\n",
    "    X = combined.drop(columns='origin')\n",
    "    y = combined['origin']\n",
    "\n",
    "    # Scale features for better classifier performance\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Train-validation split for adversarial classifier\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    # Use default classifier if none provided\n",
    "    if classifier is None:\n",
    "        classifier = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "\n",
    "    # Train classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities on validation set\n",
    "    y_pred_proba = classifier.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Calculate ROC-AUC score\n",
    "    auc_score = roc_auc_score(y_val, y_pred_proba)\n",
    "\n",
    "    return auc_score\n",
    "\n",
    "def main():\n",
    "    # Simulate train data: Normal distribution\n",
    "    np.random.seed(0)\n",
    "    train_data = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1, 1000),\n",
    "        'feature2': np.random.normal(5, 2, 1000),\n",
    "    })\n",
    "\n",
    "    # Simulate test data without drift (same distribution)\n",
    "    test_data_no_drift = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1, 500),\n",
    "        'feature2': np.random.normal(5, 2, 500),\n",
    "    })\n",
    "\n",
    "    # Simulate test data with drift (shifted mean)\n",
    "    test_data_with_drift = pd.DataFrame({\n",
    "        'feature1': np.random.normal(1, 1, 500),\n",
    "        'feature2': np.random.normal(6, 2, 500),\n",
    "    })\n",
    "\n",
    "    # No drift case\n",
    "    auc_no_drift = adversarial_validation(train_data, test_data_no_drift)\n",
    "    print(f\"ROC-AUC (No Drift): {auc_no_drift:.4f} (Close to 0.5 means no drift)\")\n",
    "\n",
    "    # Drift case\n",
    "    auc_with_drift = adversarial_validation(train_data, test_data_with_drift)\n",
    "    print(f\"ROC-AUC (With Drift): {auc_with_drift:.4f} (Closer to 1 means drift detected)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
