{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Adversarial Validation for Data Drift\n",
    "Description: Create and train a classifier that distinguishes between train and test datasets, using the classifierâ€™s performance to infer data drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (No Drift): 0.4932 (Close to 0.5 means no drift)\n",
      "ROC-AUC (With Drift): 0.7384 (Closer to 1 means drift detected)\n"
     ]
    }
   ],
   "source": [
    "# write your code from here\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def validate_dataframes(df_train, df_test):\n",
    "    if not isinstance(df_train, pd.DataFrame) or not isinstance(df_test, pd.DataFrame):\n",
    "        raise TypeError(\"Both inputs must be pandas DataFrames.\")\n",
    "    if df_train.shape[1] != df_test.shape[1]:\n",
    "        raise ValueError(\"Train and test data must have the same number of columns.\")\n",
    "    if df_train.isnull().any().any() or df_test.isnull().any().any():\n",
    "        raise ValueError(\"Input data contains missing values. Please handle them before.\")\n",
    "\n",
    "def adversarial_validation(df_train, df_test, classifier=None, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Performs adversarial validation by training a classifier to distinguish train vs test samples.\n",
    "\n",
    "    Parameters:\n",
    "    - df_train (pd.DataFrame): Training dataset features\n",
    "    - df_test (pd.DataFrame): Test dataset features\n",
    "    - classifier: sklearn classifier instance (default RandomForestClassifier)\n",
    "    - test_size (float): Fraction of data to use for validation split\n",
    "    - random_state (int): Random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - auc_score (float): ROC-AUC score on validation set\n",
    "    \"\"\"\n",
    "\n",
    "    validate_dataframes(df_train, df_test)\n",
    "\n",
    "    # Label the datasets: 0 for train, 1 for test\n",
    "    df_train_labeled = df_train.copy()\n",
    "    df_train_labeled['origin'] = 0\n",
    "\n",
    "    df_test_labeled = df_test.copy()\n",
    "    df_test_labeled['origin'] = 1\n",
    "\n",
    "    # Combine datasets\n",
    "    combined = pd.concat([df_train_labeled, df_test_labeled], axis=0).reset_index(drop=True)\n",
    "\n",
    "    X = combined.drop(columns='origin')\n",
    "    y = combined['origin']\n",
    "\n",
    "    # Scale features for better classifier performance\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Train-validation split for adversarial classifier\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    # Use default classifier if none provided\n",
    "    if classifier is None:\n",
    "        classifier = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "\n",
    "    # Train classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities on validation set\n",
    "    y_pred_proba = classifier.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Calculate ROC-AUC score\n",
    "    auc_score = roc_auc_score(y_val, y_pred_proba)\n",
    "\n",
    "    return auc_score\n",
    "\n",
    "def main():\n",
    "    # Simulate train data: Normal distribution\n",
    "    np.random.seed(0)\n",
    "    train_data = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1, 1000),\n",
    "        'feature2': np.random.normal(5, 2, 1000),\n",
    "    })\n",
    "\n",
    "    # Simulate test data without drift (same distribution)\n",
    "    test_data_no_drift = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1, 500),\n",
    "        'feature2': np.random.normal(5, 2, 500),\n",
    "    })\n",
    "\n",
    "    # Simulate test data with drift (shifted mean)\n",
    "    test_data_with_drift = pd.DataFrame({\n",
    "        'feature1': np.random.normal(1, 1, 500),\n",
    "        'feature2': np.random.normal(6, 2, 500),\n",
    "    })\n",
    "\n",
    "    # No drift case\n",
    "    auc_no_drift = adversarial_validation(train_data, test_data_no_drift)\n",
    "    print(f\"ROC-AUC (No Drift): {auc_no_drift:.4f} (Close to 0.5 means no drift)\")\n",
    "\n",
    "    # Drift case\n",
    "    auc_with_drift = adversarial_validation(train_data, test_data_with_drift)\n",
    "    print(f\"ROC-AUC (With Drift): {auc_with_drift:.4f} (Closer to 1 means drift detected)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
