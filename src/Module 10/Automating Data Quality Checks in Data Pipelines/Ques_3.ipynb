{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Data Quality Monitoring\n",
    "**Objective**: Use Great Expectations to perform data profiling and write validation rules.\n",
    "\n",
    "1. Data Profiling with Great Expectations\n",
    "\n",
    "### Profile a JSON dataset with product sales data to check for null values in the 'ProductID' and 'Price' fields.\n",
    "- Create an expectation suite and connect it to the data context.\n",
    "- Use the `expect_column_values_to_not_be_null` expectation to profile these fields.\n",
    "- Review the summary to identify any unexpected null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Running Unit Test...\n",
      "‚ùå Error setting up data context:\n",
      "‚ùå Unexpected error: module 'great_expectations.data_context' has no attribute 'DataContext'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5560/983198734.py\", line 16, in setup_context\n",
      "    return ge.data_context.DataContext(project_config=config)\n",
      "AttributeError: module 'great_expectations.data_context' has no attribute 'DataContext'. Did you mean: 'data_context'?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "from great_expectations.data_context.types.base import DataContextConfig, FilesystemStoreBackendDefaults\n",
    "import traceback\n",
    "\n",
    "# -------------------- Setup Functions --------------------\n",
    "def setup_context():\n",
    "    \"\"\"Initializes a Great Expectations context in local directory.\"\"\"\n",
    "    context_dir = \"great_expectations\"\n",
    "    try:\n",
    "        if not os.path.exists(context_dir):\n",
    "            config = DataContextConfig(\n",
    "                store_backend_defaults=FilesystemStoreBackendDefaults(root_directory=context_dir)\n",
    "            )\n",
    "            return ge.data_context.DataContext(project_config=config)\n",
    "        return ge.data_context.DataContext(context_dir)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error setting up data context:\")\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "def add_datasource(context):\n",
    "    \"\"\"Adds an in-memory pandas datasource.\"\"\"\n",
    "    config = {\n",
    "        \"name\": \"pandas_datasource\",\n",
    "        \"class_name\": \"Datasource\",\n",
    "        \"execution_engine\": {\"class_name\": \"PandasExecutionEngine\"},\n",
    "        \"data_connectors\": {\n",
    "            \"runtime_data_connector\": {\n",
    "                \"class_name\": \"RuntimeDataConnector\",\n",
    "                \"batch_identifiers\": [\"id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        context.add_datasource(**config)\n",
    "    except Exception:\n",
    "        pass  # Ignore if already added\n",
    "\n",
    "# -------------------- Validation Function --------------------\n",
    "def validate_sales_data(df, context, suite_name=\"product_sales_suite\"):\n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty. Cannot run validation.\")\n",
    "\n",
    "    batch_request = {\n",
    "        \"datasource_name\": \"pandas_datasource\",\n",
    "        \"data_connector_name\": \"runtime_data_connector\",\n",
    "        \"data_asset_name\": \"sales_data\",\n",
    "        \"runtime_parameters\": {\"batch_data\": df},\n",
    "        \"batch_identifiers\": {\"id\": \"batch_1\"}\n",
    "    }\n",
    "\n",
    "    # Create or overwrite suite\n",
    "    context.create_expectation_suite(expectation_suite_name=suite_name, overwrite_existing=True)\n",
    "    validator = context.get_validator(batch_request=batch_request, expectation_suite_name=suite_name)\n",
    "\n",
    "    # Profiling expectations\n",
    "    validator.expect_column_values_to_not_be_null(\"ProductID\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Price\")\n",
    "\n",
    "    # Validation rules for ingestion\n",
    "    validator.expect_column_values_to_be_in_set(\"Status\", [\"Active\", \"Inactive\"])\n",
    "\n",
    "    validator.save_expectation_suite()\n",
    "    result = validator.validate()\n",
    "\n",
    "    # Output summary\n",
    "    print(\"\\nüìã Validation Results:\")\n",
    "    for res in result[\"results\"]:\n",
    "        print(f\"- {res['expectation_config']['expectation_type']} => {'‚úÖ' if res['success'] else '‚ùå'}\")\n",
    "        if not res['success']:\n",
    "            print(\"  Unexpected:\", res['result'].get(\"unexpected_values\", []))\n",
    "    return result\n",
    "\n",
    "# -------------------- Unit Test Function --------------------\n",
    "def test_sales_validation():\n",
    "    \"\"\"Simulated unit test for validating edge cases.\"\"\"\n",
    "    print(\"\\nüîé Running Unit Test...\")\n",
    "\n",
    "    # Simulated data with edge cases\n",
    "    test_data = pd.DataFrame([\n",
    "        {\"ProductID\": 1, \"Price\": 20.0, \"Status\": \"Active\"},\n",
    "        {\"ProductID\": None, \"Price\": 25.0, \"Status\": \"Active\"},         # Null ProductID\n",
    "        {\"ProductID\": 3, \"Price\": None, \"Status\": \"Inactive\"},          # Null Price\n",
    "        {\"ProductID\": 4, \"Price\": 15.0, \"Status\": \"Unknown\"},           # Invalid Status\n",
    "    ])\n",
    "\n",
    "    context = setup_context()\n",
    "    add_datasource(context)\n",
    "    results = validate_sales_data(test_data, context)\n",
    "\n",
    "    # Test assertions\n",
    "    assert not results[\"success\"], \"Test should fail due to nulls and bad 'Status'\"\n",
    "    assert any(\"expect_column_values_to_be_in_set\" in r['expectation_config']['expectation_type']\n",
    "               and not r['success'] for r in results[\"results\"]), \"Invalid status should be caught.\"\n",
    "    assert any(\"expect_column_values_to_not_be_null\" in r['expectation_config']['expectation_type']\n",
    "               and not r['success'] for r in results[\"results\"]), \"Null values should be caught.\"\n",
    "\n",
    "    print(\"‚úÖ Unit Test Passed.\")\n",
    "\n",
    "# -------------------- Entry Point --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        test_sales_validation()\n",
    "        print(\"\\n‚úÖ All checks passed.\")\n",
    "    except AssertionError as e:\n",
    "        print(\"‚ùå Assertion failed:\", e)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Unexpected error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Writing Validation Rules for Data Ingestion\n",
    "\n",
    "### Define validation rules for an API data source to confirm that 'Status' field contains only predefined statuses ('Active', 'Inactive').\n",
    "\n",
    "- Apply `expect_column_values_to_be_in_set` to check field values during data ingestion.\n",
    "- Execute the validation and review any mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
