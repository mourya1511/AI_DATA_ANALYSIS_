{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Data Quality Monitoring\n",
    "**Objective**: Use Great Expectations to perform data profiling and write validation rules.\n",
    "\n",
    "1. Data Profiling with Great Expectations\n",
    "\n",
    "### Profile a JSON dataset with product sales data to check for null values in the 'ProductID' and 'Price' fields.\n",
    "- Create an expectation suite and connect it to the data context.\n",
    "- Use the `expect_column_values_to_not_be_null` expectation to profile these fields.\n",
    "- Review the summary to identify any unexpected null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'great_expectations.core.expectation_configuration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgx\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpectation_configuration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationConfiguration\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataContextError\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msetup_context\u001b[39m(context_root_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreat_expectations\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'great_expectations.core.expectation_configuration'"
     ]
    }
   ],
   "source": [
    "# write your code from here\n",
    "\n",
    "import great_expectations as gx\n",
    "import pandas as pd\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "from great_expectations.exceptions import DataContextError\n",
    "\n",
    "def setup_context(context_root_dir=\"great_expectations\"):\n",
    "    \"\"\"\n",
    "    Sets up the Great Expectations Data Context. Handles potential errors during context creation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        context = gx.DataContext(context_root_dir=context_root_dir)\n",
    "        return context\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating Data Context: {e}\")\n",
    "        return None\n",
    "\n",
    "def add_datasource(context, datasource_name, csv_file_path):\n",
    "    \"\"\"\n",
    "    Adds a datasource to the Great Expectations context, handling potential errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        context.add_datasource(\n",
    "            name=datasource_name,\n",
    "            class_name=\"pandas\",\n",
    "            module_name=\"great_expectations.datasource\",\n",
    "            batch_kwargs_generators={\n",
    "                \"default\": {\n",
    "                    \"class_name\": \"glob_reader\",\n",
    "                    \"base_directory\": \".\",  # Assuming CSV is in the current directory\n",
    "                    \"glob\": csv_file_path,\n",
    "                }\n",
    "            },\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding datasource: {e}\")\n",
    "        #Re-raise the exception so the caller can determine how to handle it\n",
    "        raise e #Re-raise exception\n",
    "\n",
    "def run_validation(context, datasource_name, data_asset_name, expectation_suite_name):\n",
    "    \"\"\"\n",
    "    Runs the data validation using Great Expectations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        batch_kwargs = {\"datasource\": datasource_name, \"dataset_name\": data_asset_name}\n",
    "        batch = context.get_batch(batch_kwargs, expectation_suite_name)\n",
    "\n",
    "        if batch.dataframe.empty:\n",
    "            print(\"DataFrame is empty. Skipping validation.\")\n",
    "            return False\n",
    "\n",
    "        results = context.run_validation(\n",
    "            batch_request={\n",
    "                \"datasource_name\": datasource_name,\n",
    "                \"data_asset_name\": data_asset_name,\n",
    "            },\n",
    "            expectation_suite_name=expectation_suite_name,\n",
    "            checkpoint_name=\"my_checkpoint\",  # You might need to create a checkpoint first. Can be omitted for basic validation\n",
    "        )\n",
    "\n",
    "        if not results[\"success\"]:\n",
    "            print(\"Validation failed.\")\n",
    "        else:\n",
    "            print(\"Validation successful.\")\n",
    "\n",
    "        return results[\"success\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during validation: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_expectation_suite(context, expectation_suite_name, dataframe):\n",
    "    \"\"\"\n",
    "    Creates or retrieves an expectation suite and adds expectations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        expectation_suite = context.get_expectation_suite(expectation_suite_name)\n",
    "        print(f\"Loaded existing ExpectationSuite `{expectation_suite.name}` containing {len(expectation_suite.expectations)} expectations.\")\n",
    "    except DataContextError:\n",
    "        expectation_suite = context.create_expectation_suite(\n",
    "            expectation_suite_name, overwrite_existing=True\n",
    "        )\n",
    "        print(f\"Created a new ExpectationSuite `{expectation_suite.name}`.\")\n",
    "\n",
    "    # Expectation 1: Check for null values in any column\n",
    "    expectation_configuration = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={},\n",
    "    )\n",
    "    for col in dataframe.columns:  # Apply to all columns\n",
    "        expectation_configuration.kwargs['column'] = col\n",
    "        expectation_suite.add_expectation(expectation_configuration)\n",
    "\n",
    "    # Expectation 2: Validate 'Status' field values (example)\n",
    "    expectation_configuration = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_in_set\",\n",
    "        kwargs={\n",
    "            \"column\": \"Status\",\n",
    "            \"value_set\": [\"Active\", \"Inactive\", \"Pending\"],\n",
    "            \"mostly\": 1.0,  # Expect all values to be in the set\n",
    "        },\n",
    "    )\n",
    "    expectation_suite.add_expectation(expectation_configuration)\n",
    "\n",
    "    context.save_expectation_suite(expectation_suite)\n",
    "    return expectation_suite\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    context_root_dir = \"great_expectations\"\n",
    "    datasource_name = \"my_pandas_datasource\"\n",
    "    data_asset_name = \"my_data_asset\"\n",
    "    csv_file_path = \"data.csv\"  # Replace with your actual CSV file\n",
    "    expectation_suite_name = \"my_expectation_suite\"\n",
    "\n",
    "\n",
    "    # Create a dummy data.csv for demonstration\n",
    "    data = {'ID': [1, 2, 3, 4, 5],\n",
    "            'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "            'Status': ['Active', 'Inactive', 'Active', 'Pending', 'Active'],\n",
    "            'Value': [10, None, 30, 40, 50]}\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"data.csv\", index=False)\n",
    "\n",
    "\n",
    "    # 1. Setup Data Context\n",
    "    context = setup_context(context_root_dir)\n",
    "    if context is None:\n",
    "        exit()\n",
    "\n",
    "    # 2. Add Datasource\n",
    "    try:\n",
    "      add_datasource(context, datasource_name, csv_file_path)\n",
    "    except Exception as e:\n",
    "      print(\"Failed to add datasource, exiting.\")\n",
    "      exit() #exit if datasource creation failed\n",
    "\n",
    "    #Load dataframe\n",
    "    dataframe = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # 3. Create/Load Expectation Suite\n",
    "    expectation_suite = create_expectation_suite(context, expectation_suite_name, dataframe)\n",
    "\n",
    "\n",
    "    # 4. Run Validation\n",
    "    validation_result = run_validation(context, datasource_name, data_asset_name, expectation_suite_name)\n",
    "\n",
    "    if validation_result:\n",
    "        print(\"Data validation was successful.\")\n",
    "    else:\n",
    "        print(\"Data validation failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Writing Validation Rules for Data Ingestion\n",
    "\n",
    "### Define validation rules for an API data source to confirm that 'Status' field contains only predefined statuses ('Active', 'Inactive').\n",
    "\n",
    "- Apply `expect_column_values_to_be_in_set` to check field values during data ingestion.\n",
    "- Execute the validation and review any mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
