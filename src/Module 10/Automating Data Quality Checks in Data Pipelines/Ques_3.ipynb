{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Data Quality Monitoring\n",
    "**Objective**: Use Great Expectations to perform data profiling and write validation rules.\n",
    "\n",
    "1. Data Profiling with Great Expectations\n",
    "\n",
    "### Profile a JSON dataset with product sales data to check for null values in the 'ProductID' and 'Price' fields.\n",
    "- Create an expectation suite and connect it to the data context.\n",
    "- Use the `expect_column_values_to_not_be_null` expectation to profile these fields.\n",
    "- Review the summary to identify any unexpected null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error during validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5560/519439083.py\", line 89, in <module>\n",
      "    context = setup_context()\n",
      "  File \"/tmp/ipykernel_5560/519439083.py\", line 26, in setup_context\n",
      "    context = ge.data_context.DataContext(project_config=config)\n",
      "AttributeError: module 'great_expectations.data_context' has no attribute 'DataContext'. Did you mean: 'data_context'?\n"
     ]
    }
   ],
   "source": [
    "# write your code from here\n",
    "\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "from great_expectations.data_context.types.base import DataContextConfig, FilesystemStoreBackendDefaults\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "# Step 1: Simulated JSON-like data (API + sales)\n",
    "sales_data = [\n",
    "    {\"ProductID\": 101, \"Price\": 29.99, \"Status\": \"Active\"},\n",
    "    {\"ProductID\": 102, \"Price\": 39.99, \"Status\": \"Inactive\"},\n",
    "    {\"ProductID\": None, \"Price\": 49.99, \"Status\": \"Active\"},\n",
    "    {\"ProductID\": 104, \"Price\": None, \"Status\": \"Pending\"},  # invalid\n",
    "    {\"ProductID\": 105, \"Price\": 19.99, \"Status\": \"Active\"},\n",
    "]\n",
    "df = pd.DataFrame(sales_data)\n",
    "\n",
    "# Step 2: Setup Great Expectations Data Context\n",
    "def setup_context():\n",
    "    context_dir = \"great_expectations\"\n",
    "    if not os.path.exists(context_dir):\n",
    "        config = DataContextConfig(\n",
    "            store_backend_defaults=FilesystemStoreBackendDefaults(root_directory=context_dir)\n",
    "        )\n",
    "        context = ge.data_context.DataContext(project_config=config)\n",
    "    else:\n",
    "        context = ge.data_context.DataContext(context_dir)\n",
    "    return context\n",
    "\n",
    "# Step 3: Add in-memory Pandas datasource\n",
    "def add_datasource(context):\n",
    "    datasource_config = {\n",
    "        \"name\": \"pandas_datasource\",\n",
    "        \"class_name\": \"Datasource\",\n",
    "        \"execution_engine\": {\"class_name\": \"PandasExecutionEngine\"},\n",
    "        \"data_connectors\": {\n",
    "            \"runtime_data_connector\": {\n",
    "                \"class_name\": \"RuntimeDataConnector\",\n",
    "                \"batch_identifiers\": [\"id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        context.add_datasource(**datasource_config)\n",
    "    except Exception:\n",
    "        pass  # Already exists\n",
    "\n",
    "# Step 4: Run validations\n",
    "def run_validations(df, context):\n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty.\")\n",
    "\n",
    "    batch_request = {\n",
    "        \"datasource_name\": \"pandas_datasource\",\n",
    "        \"data_connector_name\": \"runtime_data_connector\",\n",
    "        \"data_asset_name\": \"product_sales\",\n",
    "        \"runtime_parameters\": {\"batch_data\": df},\n",
    "        \"batch_identifiers\": {\"id\": \"batch_1\"}\n",
    "    }\n",
    "\n",
    "    suite_name = \"product_sales_suite\"\n",
    "    context.create_expectation_suite(expectation_suite_name=suite_name, overwrite_existing=True)\n",
    "    validator = context.get_validator(batch_request=batch_request, expectation_suite_name=suite_name)\n",
    "\n",
    "    # Profiling rules\n",
    "    validator.expect_column_values_to_not_be_null(\"ProductID\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Price\")\n",
    "\n",
    "    # API data validation: 'Status' must be one of predefined values\n",
    "    validator.expect_column_values_to_be_in_set(\"Status\", [\"Active\", \"Inactive\"])\n",
    "\n",
    "    validator.save_expectation_suite()\n",
    "    results = validator.validate()\n",
    "\n",
    "    print(\"\\nüìä Validation Summary:\")\n",
    "    for r in results[\"results\"]:\n",
    "        expectation = r[\"expectation_config\"][\"expectation_type\"]\n",
    "        success = r[\"success\"]\n",
    "        failed_values = r[\"result\"].get(\"unexpected_values\", [])\n",
    "        print(f\"- {expectation} => {'‚úÖ Passed' if success else '‚ùå Failed'}\")\n",
    "        if not success:\n",
    "            print(f\"  Unexpected: {failed_values}\")\n",
    "    return results\n",
    "\n",
    "# Step 5: Run everything\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        context = setup_context()\n",
    "        add_datasource(context)\n",
    "        result = run_validations(df, context)\n",
    "        print(\"\\n‚úÖ Validation complete.\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error during validation:\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Writing Validation Rules for Data Ingestion\n",
    "\n",
    "### Define validation rules for an API data source to confirm that 'Status' field contains only predefined statuses ('Active', 'Inactive').\n",
    "\n",
    "- Apply `expect_column_values_to_be_in_set` to check field values during data ingestion.\n",
    "- Execute the validation and review any mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
