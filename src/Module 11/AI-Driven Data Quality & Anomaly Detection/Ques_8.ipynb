{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLP for Text Data Quality\n",
    "**Objective**: Enhance text data quality using NLP techniques.\n",
    "\n",
    "**Task**: Removing Stopwords\n",
    "\n",
    "**Steps**:\n",
    "1. Data Set: Use a dataset of text product descriptions.\n",
    "2. Stopword Removal: Utilize an NLP library (e.g., NLTK) to remove stopwords from the\n",
    "descriptions.\n",
    "3. Assess Impact: Examine the effectiveness by analyzing word frequency before and after\n",
    "removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# write your code from here\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# write your code from here\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "# Download required resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 1: Sample Product Description Dataset\n",
    "# ----------------------------------------\n",
    "data = {\n",
    "    'ProductID': [101, 102, 103, 104],\n",
    "    'Description': [\n",
    "        \"This is a high-quality wireless Bluetooth speaker with amazing sound!\",\n",
    "        \"Elegant and durable leather wallet for men with multiple card slots.\",\n",
    "        \"A fast-charging, lightweight power bank with dual USB ports.\",\n",
    "        \"Eco-friendly water bottle made of stainless steel, perfect for travel.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 2: Define stopword removal function\n",
    "# ----------------------------------------\n",
    "def remove_stopwords(text):\n",
    "    try:\n",
    "        if not isinstance(text, str):\n",
    "            raise ValueError(\"Invalid input. Must be a string.\")\n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = word_tokenize(text.lower())  # lowercase and tokenize\n",
    "        tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "        return \" \".join(tokens)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 3: Apply to dataset\n",
    "# ----------------------------------------\n",
    "df['CleanedDescription'] = df['Description'].apply(remove_stopwords)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 4: Frequency analysis\n",
    "# ----------------------------------------\n",
    "def get_word_freq(texts):\n",
    "    all_words = \" \".join(texts).lower().split()\n",
    "    return Counter(all_words)\n",
    "\n",
    "original_freq = get_word_freq(df['Description'])\n",
    "cleaned_freq = get_word_freq(df['CleanedDescription'])\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 5: Plotting\n",
    "# ----------------------------------------\n",
    "def plot_top_words(freq_dict, title, n=10):\n",
    "    common = freq_dict.most_common(n)\n",
    "    words, counts = zip(*common)\n",
    "    sns.barplot(x=list(counts), y=list(words), palette='viridis')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Original Word Frequency (Top 10):\")\n",
    "plot_top_words(original_freq, \"Before Stopword Removal\")\n",
    "\n",
    "print(\"Cleaned Word Frequency (Top 10):\")\n",
    "plot_top_words(cleaned_freq, \"After Stopword Removal\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Optional: Show before vs after\n",
    "# ----------------------------------------\n",
    "print(\"\\n=== Example Descriptions (Before vs After) ===\")\n",
    "for i in range(len(df)):\n",
    "    print(f\"\\nOriginal: {df['Description'][i]}\")\n",
    "    print(f\"Cleaned : {df['CleanedDescription'][i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
