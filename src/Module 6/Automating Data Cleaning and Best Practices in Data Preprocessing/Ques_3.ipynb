{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Data Preprocessing\n",
    "\n",
    "#### Always Explore & Visualize Data First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loaded diabetes dataset.\n",
      "INFO: Simulated missing and infinite values.\n",
      "INFO: Replaced infinite values with NaN.\n",
      "INFO: Dropped columns with all missing values.\n",
      "INFO: Applied mean imputation.\n",
      "INFO: Applied outlier capping at 1% and 99% percentiles.\n",
      "INFO: Minmax scaling applied successfully.\n",
      "INFO: Robust scaling applied successfully.\n",
      "INFO: Maxabs scaling applied successfully.\n",
      "INFO: Saved transformation parameters to 'transformation_parameters.json'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import json\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Load Dataset\n",
    "# ----------------------------\n",
    "try:\n",
    "    data = load_diabetes()\n",
    "    X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "    logging.info(\"Loaded diabetes dataset.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Dataset loading failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Simulate Missing and Infinite Values\n",
    "# ----------------------------\n",
    "rng = np.random.RandomState(42)\n",
    "X[rng.rand(*X.shape) < 0.1] = np.nan\n",
    "X.iloc[0, 0] = np.inf\n",
    "X.iloc[1, 1] = -np.inf\n",
    "\n",
    "logging.info(\"Simulated missing and infinite values.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Clean Anomalies\n",
    "# ----------------------------\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "logging.info(\"Replaced infinite values with NaN.\")\n",
    "\n",
    "# Drop columns with all missing values\n",
    "X = X.dropna(axis=1, how='all')\n",
    "logging.info(\"Dropped columns with all missing values.\")\n",
    "\n",
    "# Check for numeric columns\n",
    "if not all(np.issubdtype(dtype, np.number) for dtype in X.dtypes):\n",
    "    raise TypeError(\"Non-numeric column detected. Please convert all data to numeric before preprocessing.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: Imputation\n",
    "# ----------------------------\n",
    "try:\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    logging.info(\"Applied mean imputation.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Imputation failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# ----------------------------\n",
    "# Step 5: Outlier Capping\n",
    "# ----------------------------\n",
    "def cap_outliers_vectorized(df, lower_q=0.01, upper_q=0.99):\n",
    "    lower = df.quantile(lower_q)\n",
    "    upper = df.quantile(upper_q)\n",
    "    return df.clip(lower=lower, upper=upper, axis=1)\n",
    "\n",
    "try:\n",
    "    X_capped = cap_outliers_vectorized(X_imputed)\n",
    "    logging.info(\"Applied outlier capping at 1% and 99% percentiles.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Outlier capping failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# ----------------------------\n",
    "# Step 6: Scaling\n",
    "# ----------------------------\n",
    "scalers = {\n",
    "    'minmax': MinMaxScaler(),\n",
    "    'robust': RobustScaler(),\n",
    "    'maxabs': MaxAbsScaler()\n",
    "}\n",
    "scaled_outputs = {}\n",
    "scaler_params = {}\n",
    "\n",
    "for name, scaler in scalers.items():\n",
    "    try:\n",
    "        X_scaled = pd.DataFrame(scaler.fit_transform(X_capped), columns=X.columns)\n",
    "        scaled_outputs[name] = X_scaled\n",
    "        logging.info(f\"{name.title()} scaling applied successfully.\")\n",
    "        \n",
    "        # Save params\n",
    "        if name == 'minmax':\n",
    "            scaler_params['minmax_min'] = scaler.data_min_.tolist()\n",
    "            scaler_params['minmax_max'] = scaler.data_max_.tolist()\n",
    "        elif name == 'robust':\n",
    "            scaler_params['robust_center'] = scaler.center_.tolist()\n",
    "            scaler_params['robust_scale'] = scaler.scale_.tolist()\n",
    "        elif name == 'maxabs':\n",
    "            scaler_params['maxabs_max'] = scaler.max_abs_.tolist()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"{name.title()} scaling failed: {e}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Step 7: Save Transformation Parameters\n",
    "# ----------------------------\n",
    "scaler_params['imputer_statistics'] = imputer.statistics_.tolist()\n",
    "\n",
    "with open('transformation_parameters.json', 'w') as f:\n",
    "    json.dump(scaler_params, f)\n",
    "\n",
    "logging.info(\"Saved transformation parameters to 'transformation_parameters.json'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing & Inconsistent Data Before Applying ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-v] [-q] [--locals] [-f] [-c] [-b]\n",
      "                             [-k TESTNAMEPATTERNS]\n",
      "                             [tests ...]\n",
      "ipykernel_launcher.py: error: argument -f/--failfast: ignored explicit argument '/home/vscode/.local/share/jupyter/runtime/kernel-v383b53d707e08e3c1984ada641f7c6a2f1931e876.json'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Include function directly if no import\n",
    "def cap_outliers_vectorized(df, lower_q=0.01, upper_q=0.99):\n",
    "    lower = df.quantile(lower_q)\n",
    "    upper = df.quantile(upper_q)\n",
    "    return df.clip(lower=lower, upper=upper, axis=1)\n",
    "\n",
    "class TestPreprocessing(unittest.TestCase):\n",
    "\n",
    "    def test_imputation(self):\n",
    "        df = pd.DataFrame({'A': [1, np.nan, 3], 'B': [4, 5, np.nan]})\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_imp = imputer.fit_transform(df)\n",
    "        self.assertFalse(np.isnan(X_imp).any())\n",
    "\n",
    "    def test_outlier_capping(self):\n",
    "        df = pd.DataFrame({'A': [1, 100, 3, 4], 'B': [4, 5, 1000, 6]})\n",
    "        capped = cap_outliers_vectorized(df)\n",
    "        q_high = df.quantile(0.99)\n",
    "        self.assertTrue((capped <= q_high).all().all())\n",
    "\n",
    "    def test_scaling_minmax(self):\n",
    "        df = pd.DataFrame({'A': [1, 2, 3], 'B': [10, 20, 30]})\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled = scaler.fit_transform(df)\n",
    "        self.assertTrue(((scaled >= 0) & (scaled <= 1)).all())\n",
    "\n",
    "    def test_handle_infinite(self):\n",
    "        df = pd.DataFrame({'A': [1, np.inf, 2], 'B': [4, -np.inf, 6]})\n",
    "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        result = imputer.fit_transform(df)\n",
    "        self.assertFalse(np.isnan(result).any())\n",
    "\n",
    "    def test_all_missing_column(self):\n",
    "        df = pd.DataFrame({'A': [np.nan, np.nan], 'B': [1, 2]})\n",
    "        df_clean = df.dropna(axis=1, how='all')\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        result = imputer.fit_transform(df_clean)\n",
    "        self.assertFalse(np.isnan(result).any())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'main'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleImputer\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cap_outliers_vectorized \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTestPreprocessing\u001b[39;00m(unittest\u001b[38;5;241m.\u001b[39mTestCase):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msetUp\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'main'"
     ]
    }
   ],
   "source": [
    "# Task 4: Drop Missing Values\n",
    "\n",
    "import unittest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from main import cap_outliers_vectorized # type: ignore\n",
    "\n",
    "class TestPreprocessing(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.X = pd.DataFrame({\n",
    "            'A': [1, 2, 3, np.nan, 5, 100],\n",
    "            'B': [1, 2, 3, 4, np.nan, 6]\n",
    "        })\n",
    "\n",
    "    def test_imputer(self):\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_imp = imputer.fit_transform(self.X)\n",
    "        self.assertFalse(np.isnan(X_imp).any())\n",
    "\n",
    "    def test_scaler(self):\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_imp = pd.DataFrame(imputer.fit_transform(self.X), columns=self.X.columns)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled = scaler.fit_transform(X_imp)\n",
    "        self.assertTrue((scaled >= 0).all() and (scaled <= 1).all())\n",
    "\n",
    "    def test_outlier_capping(self):\n",
    "        capped = cap_outliers_vectorized(self.X.fillna(0))\n",
    "        self.assertFalse((capped > self.X.quantile(0.99)).any().any())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n",
    "\n",
    "\n",
    "\n",
    "# Task 5: Fill Missing Values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 6: Handling Outliers with Capping\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the Right Scaling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7: Min-Max Scaling\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 8: Robust Scaling\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 9: MaxAbs Scaling\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Track of Data Transformations for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 10: Log Data Preprocessing Steps\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 11: Store Transformation Parameters\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
