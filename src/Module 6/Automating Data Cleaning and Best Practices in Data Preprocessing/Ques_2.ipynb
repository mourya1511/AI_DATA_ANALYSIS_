{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Task: Complete Pipeline for a Dataset\n",
    "1. Objective: Build a complex pipeline with multiple transformations.\n",
    "2. Steps:\n",
    "    - Load a sample dataset.\n",
    "    - Define a transformation pipeline with both imputation and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Original DataFrame:\n",
      "    Age   Salary  Experience\n",
      "0  25.0  50000.0         1.0\n",
      "1   NaN  54000.0         2.0\n",
      "2  30.0      NaN         NaN\n",
      "3  40.0  65000.0         4.0\n",
      "4  22.0      NaN         5.0\n",
      "\n",
      "âœ… Processed DataFrame (Imputed + Scaled):\n",
      "        Age    Salary  Experience\n",
      "0 -0.695414 -1.289210   -1.414214\n",
      "1  0.000000 -0.474972   -0.707107\n",
      "2  0.122720  0.000000    0.000000\n",
      "3  1.758989  1.764182    0.707107\n",
      "4 -1.186295  0.000000    1.414214\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Step 1: Load a sample dataset\n",
    "data = {\n",
    "    'Age': [25, np.nan, 30, 40, 22],\n",
    "    'Salary': [50000, 54000, np.nan, 65000, np.nan],\n",
    "    'Experience': [1.0, 2.0, np.nan, 4.0, 5.0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"ðŸ”¹ Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Step 2: Define numerical columns for transformation\n",
    "num_features = df.columns.tolist()\n",
    "\n",
    "# Step 3: Create a preprocessing pipeline: Imputation + Scaling\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),       # Impute missing values\n",
    "    ('scaler', StandardScaler())                       # Scale numerical features\n",
    "])\n",
    "\n",
    "# Step 4: Combine into a ColumnTransformer (useful if you later add categorical features)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, num_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 5: Apply the pipeline\n",
    "processed_data = preprocessor.fit_transform(df)\n",
    "\n",
    "# Step 6: Convert back to DataFrame for readability\n",
    "processed_df = pd.DataFrame(processed_data, columns=num_features)\n",
    "print(\"\\nâœ… Processed DataFrame (Imputed + Scaled):\")\n",
    "print(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Imputation Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scaling Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combined Transformation Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
