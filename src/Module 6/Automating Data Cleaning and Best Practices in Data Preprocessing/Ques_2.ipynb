{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Task: Complete Pipeline for a Dataset\n",
    "1. Objective: Build a complex pipeline with multiple transformations.\n",
    "2. Steps:\n",
    "    - Load a sample dataset.\n",
    "    - Define a transformation pipeline with both imputation and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Original DataFrame:\n",
      "    Age   Salary  Experience\n",
      "0  25.0  50000.0         1.0\n",
      "1   NaN  54000.0         2.0\n",
      "2  30.0      NaN         NaN\n",
      "3  40.0  65000.0         4.0\n",
      "4  22.0      NaN         5.0\n",
      "\n",
      "âœ… Processed DataFrame (Imputed + Scaled):\n",
      "        Age    Salary  Experience\n",
      "0 -0.695414 -1.289210   -1.414214\n",
      "1  0.000000 -0.474972   -0.707107\n",
      "2  0.122720  0.000000    0.000000\n",
      "3  1.758989  1.764182    0.707107\n",
      "4 -1.186295  0.000000    1.414214\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Step 1: Load a sample dataset\n",
    "data = {\n",
    "    'Age': [25, np.nan, 30, 40, 22],\n",
    "    'Salary': [50000, 54000, np.nan, 65000, np.nan],\n",
    "    'Experience': [1.0, 2.0, np.nan, 4.0, 5.0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"ðŸ”¹ Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Step 2: Define numerical columns for transformation\n",
    "num_features = df.columns.tolist()\n",
    "\n",
    "# Step 3: Create a preprocessing pipeline: Imputation + Scaling\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),       # Impute missing values\n",
    "    ('scaler', StandardScaler())                       # Scale numerical features\n",
    "])\n",
    "\n",
    "# Step 4: Combine into a ColumnTransformer (useful if you later add categorical features)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, num_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 5: Apply the pipeline\n",
    "processed_data = preprocessor.fit_transform(df)\n",
    "\n",
    "# Step 6: Convert back to DataFrame for readability\n",
    "processed_df = pd.DataFrame(processed_data, columns=num_features)\n",
    "print(\"\\nâœ… Processed DataFrame (Imputed + Scaled):\")\n",
    "print(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Imputation Function\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load Sample Dataset\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Introduce some missing values for demonstration\n",
    "rng = np.random.RandomState(42)\n",
    "missing_mask = rng.rand(*X.shape) < 0.1  # 10% missing\n",
    "X[missing_mask] = np.nan\n",
    "\n",
    "# Step 2: Define Imputation Function (using SimpleImputer)\n",
    "# Step 3: Define Scaling Function (using StandardScaler)\n",
    "# Step 4: Combine Imputation + Scaling in a Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Step 2: Imputation\n",
    "    ('scaler', StandardScaler())                  # Step 3: Scaling\n",
    "])\n",
    "\n",
    "# Step 5: Apply the Combined Transformation\n",
    "X_transformed = pipeline.fit_transform(X)\n",
    "\n",
    "# Optional: Print the shape and preview transformed data\n",
    "print(\"Transformed shape:\", X_transformed.shape)\n",
    "print(\"First 5 rows:\\n\", X_transformed[:5])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scaling Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combined Transformation Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
